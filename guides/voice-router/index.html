<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <title>Voice Router</title>
  <style>
    * { box-sizing: border-box; margin: 0; padding: 0; }
    body {
      font-family: -apple-system, BlinkMacSystemFont, sans-serif;
      background: #1a1a2e;
      color: #fff;
      min-height: 100vh;
      display: flex;
      flex-direction: column;
      align-items: center;
      padding: 20px;
      padding-top: 50px;
    }
    h1 { font-size: 24px; margin-bottom: 10px; }
    .status-area { margin-bottom: 15px; text-align: center; }
    .status { color: #888; font-size: 13px; margin: 4px 0; }
    .btn {
      width: 120px;
      height: 120px;
      border-radius: 50%;
      border: none;
      font-size: 16px;
      font-weight: 600;
      cursor: pointer;
      transition: all 0.2s;
      display: flex;
      align-items: center;
      justify-content: center;
    }
    .btn-start {
      background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
      color: #fff;
    }
    .btn-stop {
      background: linear-gradient(135deg, #f5576c 0%, #f093fb 100%);
      color: #fff;
      animation: pulse 1.5s infinite;
    }
    .btn-send {
      background: linear-gradient(135deg, #11998e 0%, #38ef7d 100%);
      color: #fff;
      width: 100px;
      height: 100px;
    }
    .btn-cancel {
      background: #444;
      color: #fff;
      width: 100px;
      height: 100px;
    }
    #recordingBtns {
      display: flex;
      gap: 20px;
    }
    @keyframes pulse {
      0%, 100% { transform: scale(1); }
      50% { transform: scale(1.05); }
    }
    .btn:active { transform: scale(0.95); }
    
    .chat-container {
      margin-top: 20px;
      width: 100%;
      max-width: 400px;
      flex: 1;
      display: flex;
      flex-direction: column;
      overflow: hidden;
    }
    .chat-messages {
      flex: 1;
      overflow-y: auto;
      padding: 10px;
      background: #2a2a4a;
      border-radius: 12px;
      margin-bottom: 10px;
    }
    .msg {
      margin-bottom: 12px;
      padding: 12px 16px;
      border-radius: 16px;
      max-width: 90%;
      font-size: 15px;
      line-height: 1.6;
      word-wrap: break-word;
    }
    .msg-user {
      background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
      color: #fff;
      margin-left: auto;
      border-bottom-right-radius: 4px;
    }
    .msg-agent {
      background: #3a3a5a;
      color: #fff;
      margin-right: auto;
      border-bottom-left-radius: 4px;
    }
    .msg-agent strong {
      color: #a0a0ff;
    }
    .msg-pending {
      opacity: 0.6;
      font-style: italic;
    }
    .msg-time {
      font-size: 10px;
      color: #888;
      margin-top: 4px;
    }
    .agent-name {
      font-size: 11px;
      color: #667eea;
      margin-bottom: 4px;
    }
    
    /* Config bar */
    .config-bar {
      display: flex;
      gap: 20px;
      margin-bottom: 15px;
      padding: 10px 15px;
      background: #2a2a4a;
      border-radius: 12px;
    }
    .toggle-label {
      display: flex;
      align-items: center;
      gap: 8px;
      font-size: 13px;
      color: #aaa;
      cursor: pointer;
    }
    .toggle-label input {
      display: none;
    }
    .toggle-slider {
      width: 40px;
      height: 22px;
      background: #444;
      border-radius: 11px;
      position: relative;
      transition: background 0.2s;
    }
    .toggle-slider::after {
      content: '';
      position: absolute;
      width: 18px;
      height: 18px;
      background: #fff;
      border-radius: 50%;
      top: 2px;
      left: 2px;
      transition: transform 0.2s;
    }
    .toggle-label input:checked + .toggle-slider {
      background: #667eea;
    }
    .toggle-label input:checked + .toggle-slider::after {
      transform: translateX(18px);
    }
    
    /* Duration buttons */
    .duration-btn {
      padding: 6px 12px;
      background: #444;
      border-radius: 8px;
      font-size: 13px;
      color: #aaa;
      cursor: pointer;
      transition: all 0.2s;
    }
    .toggle-label input[type="radio"] {
      display: none;
    }
    .toggle-label input[type="radio"]:checked + .duration-btn {
      background: #667eea;
      color: #fff;
    }
    
    /* Recording timer */
    .record-timer {
      font-size: 24px;
      font-weight: bold;
      color: #f5576c;
      margin: 10px 0;
      font-variant-numeric: tabular-nums;
    }
    .record-timer.warning {
      animation: timer-pulse 0.5s infinite;
    }
    @keyframes timer-pulse {
      0%, 100% { opacity: 1; }
      50% { opacity: 0.5; }
    }
    
    /* Noise floor meter */
    .noise-meter {
      width: 100%;
      max-width: 300px;
      margin: 10px 0;
    }
    .noise-bar-container {
      height: 20px;
      background: #2a2a4a;
      border-radius: 10px;
      overflow: hidden;
      position: relative;
    }
    .noise-bar {
      height: 100%;
      background: linear-gradient(90deg, #38ef7d 0%, #f5af19 50%, #f5576c 100%);
      border-radius: 10px;
      width: 0%;
      transition: width 0.05s;
    }
    .noise-threshold {
      position: absolute;
      top: 0;
      bottom: 0;
      width: 2px;
      background: #fff;
      opacity: 0.8;
    }
    .noise-labels {
      display: flex;
      justify-content: space-between;
      font-size: 10px;
      color: #666;
      margin-top: 4px;
    }
    .db-value {
      font-size: 12px;
      color: #888;
      margin-top: 4px;
      text-align: center;
    }
    .vad-status {
      font-size: 11px;
      color: #38ef7d;
      margin-top: 4px;
      text-align: center;
    }
    .vad-status.silent {
      color: #888;
    }
  </style>
</head>
<body>
  <h1>üéôÔ∏è Voice</h1>
  
  <div class="config-bar" id="configBar">
    <label class="toggle-label">
      <span>Edit before send</span>
      <input type="checkbox" id="editToggle" checked onchange="saveConfig()">
      <span class="toggle-slider"></span>
    </label>
    <label class="toggle-label">
      <span>Continuous 8s</span>
      <input type="checkbox" id="continuousToggle" onchange="saveConfig('continuous')">
      <span class="toggle-slider"></span>
    </label>
    <label class="toggle-label">
      <span>Audio Detection</span>
      <input type="checkbox" id="vadToggle" onchange="saveConfig('vad')">
      <span class="toggle-slider"></span>
    </label>
  </div>
  
  <div class="config-bar" id="durationBar">
    <span style="font-size:12px; color:#888; margin-right:8px;">Max:</span>
    <label class="toggle-label">
      <input type="radio" name="maxDuration" value="15" onchange="saveConfig()">
      <span class="duration-btn">15s</span>
    </label>
    <label class="toggle-label">
      <input type="radio" name="maxDuration" value="30" checked onchange="saveConfig()">
      <span class="duration-btn active">30s</span>
    </label>
    <label class="toggle-label">
      <input type="radio" name="maxDuration" value="60" onchange="saveConfig()">
      <span class="duration-btn">60s</span>
    </label>
  </div>
  
  <div class="noise-meter" id="noiseMeter" style="display:none;">
    <div class="noise-bar-container">
      <div class="noise-bar" id="noiseBar"></div>
      <div class="noise-threshold" id="noiseThreshold" style="left:25%;"></div>
    </div>
    <div class="noise-labels">
      <span>-60dB</span>
      <span>-30dB</span>
      <span>0dB</span>
    </div>
    <div class="db-value" id="dbValue">-- dB</div>
    <div class="vad-status silent" id="vadStatus">Silent</div>
  </div>
  
  <div class="status-area">
    <div class="record-timer" id="recordTimer" style="display:none;">0:00</div>
    <p class="status" id="micStatus">üéôÔ∏è Ready</p>
    <p class="status" id="agentStatus">ü§ñ Idle</p>
  </div>
  
  <div id="btnContainer">
    <button class="btn btn-start" id="mainBtn" onclick="startRecording()">
      START
    </button>
  </div>
  <div id="recordingBtns" style="display:none; gap:20px;">
    <button class="btn btn-send" onclick="sendRecording()">PREVIEW</button>
    <button class="btn btn-cancel" onclick="cancelRecording()">CANCEL</button>
  </div>
  
  <div id="editContainer" style="display:none; width:100%; max-width:400px; margin-top:15px;">
    <textarea id="editText" rows="6" style="width:100%; padding:12px; border-radius:12px; border:none; background:#2a2a4a; color:#fff; font-size:15px; resize:vertical; min-height:120px;"></textarea>
    <div style="display:flex; gap:10px; margin-top:10px; justify-content:center;">
      <button class="btn btn-send" style="width:100px; height:50px; border-radius:12px;" onclick="confirmSend()">SEND</button>
      <button class="btn btn-cancel" style="width:80px; height:50px; border-radius:12px;" onclick="cancelEdit()">‚úó REDO</button>
    </div>
  </div>
  
  <div class="chat-container">
    <div class="chat-messages" id="chat">
      <div class="msg msg-agent">
        <div class="agent-name">Cerise01</div>
        Ready to listen. Tap START and speak.
      </div>
    </div>
  </div>

  <script>
    let mediaRecorder;
    let audioChunks = [];
    let isRecording = false;
    let audioContext = null;
    let analyser = null;
    let meterAnimationId = null;
    let recordingStartTime = null;
    let timerInterval = null;
    const recordTimer = document.getElementById('recordTimer');

    const btn = document.getElementById('mainBtn');
    const micStatus = document.getElementById('micStatus');
    const agentStatus = document.getElementById('agentStatus');
    const chat = document.getElementById('chat');
    const noiseMeter = document.getElementById('noiseMeter');
    const noiseBar = document.getElementById('noiseBar');
    const dbValue = document.getElementById('dbValue');
    const vadStatus = document.getElementById('vadStatus');
    const vadToggle = document.getElementById('vadToggle');
    
    // VAD state
    let vadActive = false;
    let vadSilenceStart = null;
    let vadSpeechStart = null;
    let vadChunks = [];
    let vadRecorder = null;
    const VAD_THRESHOLD_DB = -35; // dB threshold for voice detection
    const VAD_SILENCE_TIMEOUT = 1500; // ms of silence before sending
    const VAD_MIN_SPEECH = 300; // minimum ms of speech before counting
    
    // Poll for agent responses and status
    setInterval(pollResponses, 3000);
    setInterval(pollStatus, 1000);

    const btnContainer = document.getElementById('btnContainer');
    const recordingBtns = document.getElementById('recordingBtns');
    const editContainer = document.getElementById('editContainer');
    const editText = document.getElementById('editText');
    const editToggle = document.getElementById('editToggle');
    let pendingBlob = null;
    let pendingText = null;
    let continuousStream = null;
    
    // Get max duration from radio buttons
    function getMaxDuration() {
      const selected = document.querySelector('input[name="maxDuration"]:checked');
      return selected ? parseInt(selected.value) : 30;
    }
    
    // Load saved config
    function loadConfig() {
      const saved = localStorage.getItem('voiceRouterConfig');
      if (saved) {
        const config = JSON.parse(saved);
        editToggle.checked = config.editBeforeSend !== false;
        continuousToggle.checked = config.continuous === true;
        // VAD defaults to true if not explicitly set to false
        vadToggle.checked = config.vad !== false;
        // Load max duration
        if (config.maxDuration) {
          const radio = document.querySelector(`input[name="maxDuration"][value="${config.maxDuration}"]`);
          if (radio) radio.checked = true;
        }
      } else {
        // First load defaults: VAD on, edit off for voice-first experience
        vadToggle.checked = true;
        editToggle.checked = false;
      }
      updateUIForMode();
    }
    
    async function saveConfig(source) {
      // If currently recording and switching modes, cleanly wrap up first
      if (isRecording && (source === 'vad' || source === 'continuous' || source === 'edit')) {
        // Determine what mode we WERE in before the toggle changed
        const wasVad = source === 'vad' ? !vadToggle.checked : (source !== 'continuous' && vadToggle.checked);
        const wasContinuous = source === 'continuous' ? !continuousToggle.checked : (source !== 'vad' && continuousToggle.checked);
        
        if (wasVad) {
          // Stop VAD mode cleanly
          await stopVadMode();
        } else if (wasContinuous) {
          // Stop continuous mode cleanly
          await stopContinuous();
        }
      }
      
      // Auto-disable mutually exclusive modes when enabling one
      if (source === 'vad' && vadToggle.checked) {
        continuousToggle.checked = false;
      } else if (source === 'continuous' && continuousToggle.checked) {
        vadToggle.checked = false;
      }
      
      const config = {
        editBeforeSend: editToggle.checked,
        continuous: continuousToggle.checked,
        vad: vadToggle.checked,
        maxDuration: getMaxDuration()
      };
      localStorage.setItem('voiceRouterConfig', JSON.stringify(config));
      updateUIForMode();
    }
    
    // Timer display functions
    function startTimer() {
      recordingStartTime = Date.now();
      recordTimer.style.display = 'block';
      recordTimer.className = 'record-timer';
      updateTimerDisplay();
      timerInterval = setInterval(updateTimerDisplay, 100);
    }
    
    function updateTimerDisplay() {
      if (!recordingStartTime) return;
      const elapsed = Math.floor((Date.now() - recordingStartTime) / 1000);
      const maxDur = getMaxDuration();
      const remaining = maxDur - elapsed;
      const mins = Math.floor(elapsed / 60);
      const secs = elapsed % 60;
      recordTimer.textContent = `${mins}:${secs.toString().padStart(2, '0')} / ${maxDur}s`;
      
      // Warning when 5 seconds left
      if (remaining <= 5 && remaining > 0) {
        recordTimer.className = 'record-timer warning';
      }
    }
    
    function stopTimer() {
      if (timerInterval) {
        clearInterval(timerInterval);
        timerInterval = null;
      }
      recordTimer.style.display = 'none';
      recordingStartTime = null;
    }
    
    function updateUIForMode() {
      const isContinuousOrVad = continuousToggle.checked || vadToggle.checked;
      const durationBar = document.getElementById('durationBar');
      
      if (isContinuousOrVad) {
        btn.textContent = 'START';
        // In continuous/VAD mode, edit is forced off
        editToggle.disabled = true;
        editToggle.parentElement.style.opacity = '0.5';
      } else {
        btn.textContent = 'START';
        editToggle.disabled = false;
        editToggle.parentElement.style.opacity = '1';
      }
      
      // Show duration selector ONLY when Audio Detection (VAD) is on
      // This sets the max duration before auto-send in VAD mode
      if (vadToggle.checked) {
        durationBar.style.display = 'flex';
      } else {
        durationBar.style.display = 'none';
      }
      
      // All mode toggles always enabled - selecting one auto-disables the other
      continuousToggle.disabled = false;
      continuousToggle.parentElement.style.opacity = '1';
      vadToggle.disabled = false;
      vadToggle.parentElement.style.opacity = '1';
    }
    
    loadConfig();

    function setupAudioAnalyser(stream) {
      audioContext = new (window.AudioContext || window.webkitAudioContext)();
      const source = audioContext.createMediaStreamSource(stream);
      analyser = audioContext.createAnalyser();
      analyser.fftSize = 2048;
      analyser.smoothingTimeConstant = 0.3;
      source.connect(analyser);
      
      noiseMeter.style.display = 'block';
      updateMeter();
    }
    
    function updateMeter() {
      if (!analyser) return;
      
      const dataArray = new Float32Array(analyser.frequencyBinCount);
      analyser.getFloatTimeDomainData(dataArray);
      
      // Calculate RMS
      let sum = 0;
      for (let i = 0; i < dataArray.length; i++) {
        sum += dataArray[i] * dataArray[i];
      }
      const rms = Math.sqrt(sum / dataArray.length);
      const db = 20 * Math.log10(rms + 0.0001);
      
      // Map -60dB to 0dB => 0% to 100%
      const percent = Math.max(0, Math.min(100, ((db + 60) / 60) * 100));
      noiseBar.style.width = percent + '%';
      dbValue.textContent = db.toFixed(1) + ' dB';
      
      // VAD logic
      if (vadToggle.checked && isRecording) {
        const isSpeech = db > VAD_THRESHOLD_DB;
        
        if (isSpeech) {
          vadStatus.textContent = 'üó£Ô∏è Speaking';
          vadStatus.className = 'vad-status';
          vadSilenceStart = null;
          
          if (!vadSpeechStart) {
            vadSpeechStart = Date.now();
          }
          
          // Start recording if not already
          if (!vadRecorder || vadRecorder.state === 'inactive') {
            startVadRecording();
          }
        } else {
          vadStatus.textContent = 'Silent';
          vadStatus.className = 'vad-status silent';
          
          // If we were speaking and now silent
          if (vadSpeechStart && vadRecorder && vadRecorder.state === 'recording') {
            if (!vadSilenceStart) {
              vadSilenceStart = Date.now();
            } else if (Date.now() - vadSilenceStart > VAD_SILENCE_TIMEOUT) {
              // Enough silence, send the audio
              const speechDuration = vadSilenceStart - vadSpeechStart;
              if (speechDuration > VAD_MIN_SPEECH) {
                stopVadRecording(true);
              } else {
                // Too short, discard
                stopVadRecording(false);
              }
            }
          }
        }
      }
      
      meterAnimationId = requestAnimationFrame(updateMeter);
    }
    
    function stopMeter() {
      if (meterAnimationId) {
        cancelAnimationFrame(meterAnimationId);
        meterAnimationId = null;
      }
      if (audioContext) {
        audioContext.close();
        audioContext = null;
        analyser = null;
      }
      noiseMeter.style.display = 'none';
    }
    
    let vadStartTime = null;
    let vadMaxDurationTimeout = null;
    
    function startVadRecording() {
      if (!continuousStream) return;
      
      vadChunks = [];
      vadStartTime = Date.now();
      vadRecorder = new MediaRecorder(continuousStream, { mimeType: 'audio/webm' });
      
      vadRecorder.ondataavailable = (e) => {
        if (e.data.size > 0) vadChunks.push(e.data);
      };
      
      vadRecorder.start(100); // Collect in 100ms chunks
      startTimer();
      console.log('VAD: Started recording');
      
      // Set max duration timeout
      const maxDur = getMaxDuration() * 1000;
      vadMaxDurationTimeout = setTimeout(() => {
        if (vadRecorder && vadRecorder.state === 'recording') {
          console.log('VAD: Max duration reached, auto-sending');
          micStatus.textContent = '‚è±Ô∏è Max duration - sending...';
          stopVadRecording(true);
        }
      }, maxDur);
    }
    
    function stopVadRecording(send) {
      if (!vadRecorder || vadRecorder.state === 'inactive') return;
      
      // Clear max duration timeout
      if (vadMaxDurationTimeout) {
        clearTimeout(vadMaxDurationTimeout);
        vadMaxDurationTimeout = null;
      }
      stopTimer();
      
      vadRecorder.onstop = async () => {
        if (send && vadChunks.length > 0) {
          const blob = new Blob(vadChunks, { type: 'audio/webm' });
          micStatus.textContent = '‚è≥ Transcribing...';
          await sendToWhisper(blob, true);
          micStatus.textContent = 'üî¥ Listening (VAD)...';
        }
        vadChunks = [];
        vadSpeechStart = null;
        vadSilenceStart = null;
        vadStartTime = null;
      };
      
      vadRecorder.stop();
      console.log('VAD: Stopped recording, send=' + send);
    }

    async function startRecording() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        
        // Always set up the meter when recording
        setupAudioAnalyser(stream);
        
        if (vadToggle.checked) {
          // VAD mode - listen and auto-detect speech
          continuousStream = stream;
          isRecording = true;
          btn.textContent = 'STOP';
          btn.className = 'btn btn-stop';
          btn.onclick = stopVadMode;
          micStatus.textContent = 'üî¥ Listening (VAD)...';
          vadSpeechStart = null;
          vadSilenceStart = null;
        } else if (continuousToggle.checked) {
          // Continuous mode
          continuousStream = stream;
          startContinuousChunk();
          isRecording = true;
          btn.textContent = 'STOP';
          btn.className = 'btn btn-stop';
          btn.onclick = stopContinuous;
          micStatus.textContent = 'üî¥ Listening...';
        } else {
          // Manual mode
          mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm' });
          audioChunks = [];
          
          mediaRecorder.ondataavailable = (e) => {
            if (e.data.size > 0) {
              audioChunks.push(e.data);
            }
          };

          mediaRecorder.onstop = async () => {
            stopTimer();
            if (audioChunks.length > 0) {
              pendingBlob = new Blob(audioChunks, { type: 'audio/webm' });
              audioChunks = [];
            }
          };

          mediaRecorder.start();
          isRecording = true;
          startTimer();
          btnContainer.style.display = 'none';
          recordingBtns.style.display = 'flex';
          micStatus.textContent = 'üî¥ Recording...';
          
          // Auto-stop at max duration
          const maxDur = getMaxDuration() * 1000;
          setTimeout(() => {
            if (mediaRecorder && mediaRecorder.state === 'recording') {
              micStatus.textContent = '‚è±Ô∏è Max duration reached';
              sendRecording();
            }
          }, maxDur);
        }
      } catch (err) {
        micStatus.textContent = '‚ùå Mic denied';
        console.error(err);
      }
    }
    
    async function stopVadMode() {
      isRecording = false;
      
      // Clear max duration timeout if active
      if (vadMaxDurationTimeout) {
        clearTimeout(vadMaxDurationTimeout);
        vadMaxDurationTimeout = null;
      }
      stopTimer();
      
      // If there's an active recording with speech, finish transcribing it
      if (vadRecorder && vadRecorder.state === 'recording' && vadSpeechStart) {
        micStatus.textContent = '‚è≥ Finishing transcription...';
        btn.textContent = '...';
        btn.disabled = true;
        
        // Create a promise that resolves when transcription is done
        await new Promise((resolve) => {
          vadRecorder.onstop = async () => {
            if (vadChunks.length > 0) {
              const blob = new Blob(vadChunks, { type: 'audio/webm' });
              await sendToWhisper(blob, true);
            }
            vadChunks = [];
            vadSpeechStart = null;
            vadSilenceStart = null;
            vadStartTime = null;
            resolve();
          };
          vadRecorder.stop();
        });
        
        btn.disabled = false;
      } else {
        // No active speech, just clean up
        if (vadRecorder && vadRecorder.state !== 'inactive') {
          vadRecorder.stop();
        }
        vadSpeechStart = null;
        vadSilenceStart = null;
        vadStartTime = null;
      }
      
      if (continuousStream) {
        continuousStream.getTracks().forEach(t => t.stop());
        continuousStream = null;
      }
      stopMeter();
      btn.textContent = 'START';
      btn.className = 'btn btn-start';
      btn.onclick = startRecording;
      micStatus.textContent = 'üéôÔ∏è Ready';
    }
    
    let transcriptionQueue = []; // Queue of blobs waiting to be transcribed
    let isTranscribing = false;
    
    async function processTranscriptionQueue() {
      if (isTranscribing || transcriptionQueue.length === 0) return;
      
      isTranscribing = true;
      while (transcriptionQueue.length > 0) {
        const blob = transcriptionQueue.shift();
        micStatus.textContent = `‚è≥ Transcribing... (${transcriptionQueue.length} queued)`;
        await sendToWhisper(blob, true);
      }
      isTranscribing = false;
      if (isRecording && continuousToggle.checked) {
        micStatus.textContent = 'üî¥ Listening...';
      }
    }
    
    function startContinuousChunk() {
      if (!continuousStream || !continuousToggle.checked || stoppingContinuous) return;
      
      const chunkRecorder = new MediaRecorder(continuousStream, { mimeType: 'audio/webm' });
      chunkRecorder._chunks = [];
      currentContinuousRecorder = chunkRecorder;
      
      chunkRecorder.ondataavailable = (e) => {
        if (e.data.size > 0) chunkRecorder._chunks.push(e.data);
      };
      
      chunkRecorder.onstop = async () => {
        // Queue for transcription instead of awaiting
        if (chunkRecorder._chunks.length > 0 && continuousToggle.checked && isRecording && !stoppingContinuous) {
          const blob = new Blob(chunkRecorder._chunks, { type: 'audio/webm' });
          transcriptionQueue.push(blob);
          processTranscriptionQueue(); // Non-blocking
        }
      };
      
      chunkRecorder.start();
      // No timer in continuous mode - it auto-loops every 8s
      // Record for 8 seconds then stop AND immediately start next
      setTimeout(() => {
        if (chunkRecorder.state !== 'inactive' && isRecording && !stoppingContinuous) {
          chunkRecorder.stop();
          // Immediately start next chunk (overlap!)
          if (continuousToggle.checked && isRecording && !stoppingContinuous) {
            startContinuousChunk();
          }
        }
      }, 8000);
    }
    
    let currentContinuousRecorder = null;
    let stoppingContinuous = false;
    
    async function stopContinuous() {
      stoppingContinuous = true;
      isRecording = false;
      
      btn.textContent = '...';
      btn.disabled = true;
      micStatus.textContent = '‚è≥ Finishing transcription...';
      
      // If there's an active chunk recording, stop it and add to queue
      if (currentContinuousRecorder && currentContinuousRecorder.state === 'recording') {
        await new Promise((resolve) => {
          currentContinuousRecorder.onstop = function() {
            if (this._chunks && this._chunks.length > 0) {
              const blob = new Blob(this._chunks, { type: 'audio/webm' });
              transcriptionQueue.push(blob);
            }
            resolve();
          };
          currentContinuousRecorder.stop();
        });
        currentContinuousRecorder = null;
      }
      
      // Process all remaining transcriptions (including the one we just added)
      if (transcriptionQueue.length > 0 || isTranscribing) {
        // Kick off processing if not already running
        processTranscriptionQueue();
        
        // Wait for queue to fully drain
        await new Promise((resolve) => {
          const checkDone = setInterval(() => {
            const remaining = transcriptionQueue.length + (isTranscribing ? 1 : 0);
            micStatus.textContent = `‚è≥ Finishing ${remaining} transcription(s)...`;
            if (transcriptionQueue.length === 0 && !isTranscribing) {
              clearInterval(checkDone);
              resolve();
            }
          }, 200);
        });
      }
      
      if (continuousStream) {
        continuousStream.getTracks().forEach(t => t.stop());
        continuousStream = null;
      }
      stopMeter();
      stoppingContinuous = false;
      btn.disabled = false;
      btn.textContent = 'START';
      btn.className = 'btn btn-start';
      btn.onclick = startRecording;
      micStatus.textContent = 'üéôÔ∏è Ready';
    }

    function sendRecording() {
      if (mediaRecorder && mediaRecorder.state !== 'inactive') {
        mediaRecorder.stop();
        mediaRecorder.stream.getTracks().forEach(t => t.stop());
      }
      isRecording = false;
      btnContainer.style.display = 'block';
      recordingBtns.style.display = 'none';
      micStatus.textContent = '‚è≥ Transcribing...';
      
      // Wait a tick for onstop to set pendingBlob
      setTimeout(async () => {
        if (pendingBlob) {
          await sendToWhisper(pendingBlob);
          pendingBlob = null;
        }
      }, 100);
    }

    function cancelRecording() {
      if (mediaRecorder && mediaRecorder.state !== 'inactive') {
        mediaRecorder.stop();
        mediaRecorder.stream.getTracks().forEach(t => t.stop());
      }
      isRecording = false;
      pendingBlob = null;
      audioChunks = [];
      stopMeter();
      stopTimer();
      btnContainer.style.display = 'block';
      recordingBtns.style.display = 'none';
      micStatus.textContent = 'üéôÔ∏è Cancelled';
    }

    async function sendToWhisper(audioBlob, autoSend = false) {
      try {
        const formData = new FormData();
        formData.append('file', audioBlob, 'audio.webm');
        
        const res = await fetch('/v1/audio/transcriptions', {
          method: 'POST',
          body: formData
        });
        
        const data = await res.json();
        const text = data.text?.trim();
        
        console.log('Whisper response:', data);
        if (text && text.length > 0) {
          // If edit is disabled OR continuous/autoSend mode, send directly
          if (!editToggle.checked || autoSend) {
            addMessage(text, 'user');
            await routeToAgent(text);
            micStatus.textContent = continuousToggle.checked ? 'üî¥ Listening...' : 'üéôÔ∏è Ready';
            btnContainer.style.display = 'block';
          } else {
            // Show edit screen
            pendingText = text;
            editText.value = text;
            editContainer.style.display = 'block';
            btnContainer.style.display = 'none';
            micStatus.textContent = '‚úèÔ∏è Edit & confirm';
          }
        } else {
          micStatus.textContent = continuousToggle.checked ? 'üî¥ Listening...' : 'üéôÔ∏è No speech detected';
          btnContainer.style.display = 'block';
          console.log('Empty text, raw response:', JSON.stringify(data));
        }
      } catch (err) {
        console.error('Whisper error:', err);
        micStatus.textContent = '‚ùå Error';
      }
    }

    async function routeToAgent(text) {
      try {
        await fetch('/route', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ text, timestamp: Date.now() })
        });
      } catch (err) {
        console.error('Route error:', err);
      }
    }

    async function confirmSend() {
      const text = editText.value.trim();
      if (text) {
        addMessage(text, 'user');
        await routeToAgent(text);
        micStatus.textContent = 'üéôÔ∏è Ready';
      }
      editContainer.style.display = 'none';
      btnContainer.style.display = 'block';
      pendingText = null;
    }

    function cancelEdit() {
      editContainer.style.display = 'none';
      btnContainer.style.display = 'block';
      pendingText = null;
      micStatus.textContent = 'üéôÔ∏è Ready - tap to retry';
    }

    async function pollResponses() {
      try {
        const res = await fetch('/responses');
        if (res.ok) {
          const data = await res.json();
          if (data.messages && data.messages.length > 0) {
            data.messages.forEach(msg => {
              addMessage(msg, 'agent');
            });
            micStatus.textContent = 'Tap to speak';
          }
        }
      } catch (err) {
        // Silently ignore polling errors
      }
    }

    function addMessage(text, type) {
      const div = document.createElement('div');
      div.className = `msg msg-${type}`;
      // Convert markdown-like formatting for agent messages
      let formatted = text
        .replace(/\*\*(.+?)\*\*/g, '<strong>$1</strong>')
        .replace(/\n- /g, '<br>‚Ä¢ ')
        .replace(/\n/g, '<br>');
      if (type === 'agent') {
        div.innerHTML = `<div class="agent-name">Cerise01</div>${formatted}`;
      } else {
        div.textContent = text;
      }
      chat.insertBefore(div, chat.firstChild);
    }

    async function pollStatus() {
      try {
        const res = await fetch('/status');
        if (res.ok) {
          const data = await res.json();
          const s = data.status;
          if (s === 'received') {
            agentStatus.textContent = 'ü§ñ Cerise01 is reading...';
          } else if (s === 'typing') {
            agentStatus.textContent = '‚úçÔ∏è Cerise01 is typing...';
          } else if (s === 'idle') {
            agentStatus.textContent = 'ü§ñ Idle';
          }
        }
      } catch (err) {}
    }
  </script>
</body>
</html>
